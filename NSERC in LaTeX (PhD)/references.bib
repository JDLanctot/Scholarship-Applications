@article{nabli_curriculum_2020,
	title = {Curriculum learning for multilevel budgeted combinatorial problems},
	volume = {abs/2007.03151},
	url = {https://arxiv.org/abs/2007.03151},
	journaltitle = {{CoRR}},
    journal = {{CoRR}},
	author = {Nabli, Adel and Carvalho, Margarida},
	urldate = {2022-01-29},
	date = {2020},
	eprinttype = {arxiv},
	eprint = {2007.03151},
    year = 2020,
}

@article{daskalakis_independent_2021,
	title = {Independent Policy Gradient Methods for Competitive Reinforcement Learning},
	volume = {abs/2101.04233},
	url = {https://arxiv.org/abs/2101.04233},
	journaltitle = {{CoRR}},
    journal = {{CoRR}},
	author = {Daskalakis, Constantinos and Foster, Dylan J. and Golowich, Noah},
	urldate = {2022-01-29},
	date = {2021},
	eprinttype = {arxiv},
	eprint = {2101.04233},
    year = 2021,
}

@article{leibo_multi-agent_2017,
	title = {Multi-agent Reinforcement Learning in Sequential Social Dilemmas},
	volume = {abs/1702.03037},
	url = {http://arxiv.org/abs/1702.03037},
	journaltitle = {{CoRR}},
    journal = {{CoRR}},
	author = {Leibo, Joel Z. and Zambaldi, Vin√≠cius Flores and Lanctot, Marc and Marecki, Janusz and Graepel, Thore},
	urldate = {2022-01-29},
	date = {2017},
	eprinttype = {arxiv},
	eprint = {1702.03037},
    year = 2017,
}

@article{curry_finding_2022,
	title = {Finding General Equilibria in Many-Agent Economic Simulations Using Deep Reinforcement Learning},
	url = {http://arxiv.org/abs/2201.01163},
	abstract = {Real economies can be seen as a sequential imperfect-information game with many heterogeneous, interacting strategic agents of various agent types, such as consumers, firms, and governments. Dynamic general equilibrium models are common economic tools to model the economic activity, interactions, and outcomes in such systems. However, existing analytical and computational methods struggle to find explicit equilibria when all agents are strategic and interact, while joint learning is unstable and challenging. Amongst others, a key reason is that the actions of one economic agent may change the reward function of another agent, e.g., a consumer's expendable income changes when firms change prices or governments change taxes. We show that multi-agent deep reinforcement learning ({RL}) can discover stable solutions that are epsilon-Nash equilibria for a meta-game over agent types, in economic simulations with many agents, through the use of structured learning curricula and efficient {GPU}-only simulation and training. Conceptually, our approach is more flexible and does not need unrealistic assumptions, e.g., market clearing, that are commonly used for analytical tractability. Our {GPU} implementation enables training and analyzing economies with a large number of agents within reasonable time frames, e.g., training completes within a day. We demonstrate our approach in real-business-cycle models, a representative family of {DGE} models, with 100 worker-consumers, 10 firms, and a government who taxes and redistributes. We validate the learned meta-game epsilon-Nash equilibria through approximate best-response analyses, show that {RL} policies align with economic intuitions, and that our approach is constructive, e.g., by explicitly learning a spectrum of meta-game epsilon-Nash equilibria in open {RBC} models.},
	journaltitle = {{arXiv}:2201.01163 [cs, econ, q-fin]},
    journal = {{arXiv}:2201.01163 [cs, econ, q-fin]},
	author = {Curry, Michael and Trott, Alexander and Phade, Soham and Bai, Yu and Zheng, Stephan},
	urldate = {2022-02-04},
	date = {2022-01-03},
	eprinttype = {arxiv},
	eprint = {2201.01163},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Science and Game Theory, Computer Science - Machine Learning, Economics - General Economics},
	file = {arXiv Fulltext PDF:C\:\\Users\\Too_Faeded\\Zotero\\storage\\5MFQIUJ4\\Curry et al. - 2022 - Finding General Equilibria in Many-Agent Economic .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Too_Faeded\\Zotero\\storage\\UP7AZPJF\\2201.html:text/html},
    year = 2022,
}

@inproceedings{dai_learning_2017,
	location = {Red Hook, {NY}, {USA}},
	title = {Learning combinatorial optimization algorithms over graphs},
	isbn = {978-1-5108-6096-4},
	series = {{NIPS}'17},
	abstract = {The design of good heuristics or approximation algorithms for {NP}-hard combinatorial optimization problems often requires significant specialized knowledge and trial-and-error. Can we automate this challenging, tedious process, and learn the algorithms instead? In many real-world applications, it is typically the case that the same optimization problem is solved again and again on a regular basis, maintaining the same problem structure but differing in the data. This provides an opportunity for learning heuristic algorithms that exploit the structure of such recurring problems. In this paper, we propose a unique combination of reinforcement learning and graph embedding to address this challenge. The learned greedy policy behaves like a meta-algorithm that incrementally constructs a solution, and the action is determined by the output of a graph embedding network capturing the current state of the solution. We show that our framework can be applied to a diverse range of optimization problems over graphs, and learns effective algorithms for the Minimum Vertex Cover, Maximum Cut and Traveling Salesman problems.},
	pages = {6351--6361},
	booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
    book = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
	publisher = {Curran Associates Inc.},
	author = {Dai, Hanjun and Khalil, Elias B. and Zhang, Yuyu and Dilkina, Bistra and Song, Le},
	urldate = {2022-03-14},
	date = {2017-12-04},
	file = {Full Text PDF:C\:\\Users\\Too_Faeded\\Zotero\\storage\\78VA5B6J\\Dai et al. - 2017 - Learning combinatorial optimization algorithms ove.pdf:application/pdf},
    year = 2017,
}

@article{bennett_percolation_2019,
	title = {On percolation and {NP}-hardness},
	volume = {54},
	issn = {10429832},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/rsa.20772},
	doi = {10.1002/rsa.20772},
	pages = {228--257},
	number = {2},
	journaltitle = {Random Structures \& Algorithms},
    journal = {Random Structures \& Algorithms},
	shortjournal = {Random Struct Alg},
	author = {Bennett, Huck and Reichman, Daniel and Shinkar, Igor},
	urldate = {2022-03-15},
	date = {2019-03},
	langid = {english},
	file = {Full Text:C\:\\Users\\Too_Faeded\\Zotero\\storage\\UATUMAP7\\Bennett et al. - 2019 - On percolation and NP-hardness.pdf:application/pdf},
    year = 2019,
}

@article{morone_influence_2015,
	title = {Influence maximization in complex networks through optimal percolation},
	volume = {524},
	issn = {0028-0836, 1476-4687},
	url = {http://arxiv.org/abs/1506.08326},
	doi = {10.1038/nature14604},
	abstract = {The whole frame of interconnections in complex networks hinges on a specific set of structural nodes, much smaller than the total size, which, if activated, would cause the spread of information to the whole network [1]; or, if immunized, would prevent the diffusion of a large scale epidemic [2,3]. Localizing this optimal, i.e. minimal, set of structural nodes, called influencers, is one of the most important problems in network science [4,5]. Despite the vast use of heuristic strategies to identify influential spreaders [6-14], the problem remains unsolved. Here, we map the problem onto optimal percolation in random networks to identify the minimal set of influencers, which arises by minimizing the energy of a many-body system, where the form of the interactions is fixed by the non-backtracking matrix [15] of the network. Big data analyses reveal that the set of optimal influencers is much smaller than the one predicted by previous heuristic centralities. Remarkably, a large number of previously neglected weakly-connected nodes emerges among the optimal influencers. These are topologically tagged as low-degree nodes surrounded by hierarchical coronas of hubs, and are uncovered only through the optimal collective interplay of all the influencers in the network. Eventually, the present theoretical framework may hold a larger degree of universality, being applicable to other hard optimization problems exhibiting a continuous transition from a known phase [16].},
	pages = {65--68},
	number = {7563},
	journaltitle = {Nature},
    journal = {Nature},
	shortjournal = {Nature},
	author = {Morone, Flaviano and Makse, Hernan A.},
	urldate = {2022-03-15},
	date = {2015-08-06},
	eprinttype = {arxiv},
	eprint = {1506.08326},
	keywords = {Computer Science - Social and Information Networks, Condensed Matter - Disordered Systems and Neural Networks, Physics - Physics and Society},
	file = {arXiv Fulltext PDF:C\:\\Users\\Too_Faeded\\Zotero\\storage\\DQ7347FX\\Morone and Makse - 2015 - Influence maximization in complex networks through.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Too_Faeded\\Zotero\\storage\\272YYANY\\1506.html:text/html},
    year = 2015,
}

@article{mnih_playing_2013,
	title = {Playing Atari with Deep Reinforcement Learning},
	abstract = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	date = {2013-12-19},
    year = 2013,
    journal={arXiv preprint arXiv:1312.5602},
}

@article{ren_generalized_2019,
	title = {Generalized network dismantling},
	volume = {116},
	issn = {0027-8424, 1091-6490},
	url = {https://pnas.org/doi/full/10.1073/pnas.1806108116},
	doi = {10.1073/pnas.1806108116},
	abstract = {Significance
            The proper functioning of many sociotechnical systems depends on their level of connectivity. By removing or deactivating a specific set of nodes, a network structure can be dismantled into isolated subcomponents, thereby disrupting the malfunctioning of a system or containing the spread of misinformation or an epidemic. We propose a generalized network-dismantling framework, which can take realistic removal costs into account such as the node price, the protection level, or removal energy. We discuss applications of cost-efficient dismantling strategies to real-world problems such as containing an epidemic or dismantling criminal or corruption networks.
          , 
            Finding an optimal subset of nodes in a network that is able to efficiently disrupt the functioning of a corrupt or criminal organization or contain an epidemic or the spread of misinformation is a highly relevant problem of network science. In this paper, we address the generalized network-dismantling problem, which aims at finding a set of nodes whose removal from the network results in the fragmentation of the network into subcritical network components at minimal overall cost. Compared with previous formulations, we allow the costs of node removals to take arbitrary nonnegative real values, which may depend on topological properties such as node centrality or on nontopological features such as the price or protection level of a node. Interestingly, we show that nonunit costs imply a significantly different dismantling strategy. To solve this optimization problem, we propose a method which is based on the spectral properties of a node-weighted Laplacian operator and combine it with a fine-tuning mechanism related to the weighted vertex cover problem. The proposed method is applicable to large-scale networks with millions of nodes. It outperforms current state-of-the-art methods and opens more directions for understanding the vulnerability and robustness of complex systems.},
	pages = {6554--6559},
	number = {14},
	journaltitle = {Proceedings of the National Academy of Sciences},
    journal = {Proceedings of the National Academy of Sciences},
	shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
	author = {Ren, Xiao-Long and Gleinig, Niels and Helbing, Dirk and Antulov-Fantulin, Nino},
	urldate = {2022-03-15},
	date = {2019-04-02},
	langid = {english},
	file = {Full Text:C\:\\Users\\Too_Faeded\\Zotero\\storage\\524FCNHB\\Ren et al. - 2019 - Generalized network dismantling.pdf:application/pdf},
    year = 2019,
}

@article{grassia_machine_2021,
	title = {Machine learning dismantling and early-warning signals of disintegration in complex systems},
	volume = {12},
	doi = {10.1038/s41467-021-25485-8},
	abstract = {From physics to engineering, biology and social science, natural and artificial systems are characterized by interconnected topologies whose features ‚Äì e.g., heterogeneous connectivity, mesoscale organization, hierarchy ‚Äì affect their robustness to external perturbations, such as targeted attacks to their units. Identifying the minimal set of units to attack to disintegrate a complex network, i.e. network dismantling, is a computationally challenging ({NP}-hard) problem which is usually attacked with heuristics. Here, we show that a machine trained to dismantle relatively small systems is able to identify higher-order topological patterns, allowing to disintegrate large-scale social, infrastructural and technological networks more efficiently than human-based heuristics. Remarkably, the machine assesses the probability that next attacks will disintegrate the system, providing a quantitative method to quantify systemic risk and detect early-warning signals of system‚Äôs collapse. This demonstrates that machine-assisted analysis can be effectively used for policy and decision-making to better quantify the fragility of complex systems and their response to shocks.},
	journaltitle = {Nature Communications},
    journal = {Nature Communications},
	shortjournal = {Nature Communications},
	author = {Grassia, Marco and De Domenico, Manlio and Mangioni, Giuseppe},
	date = {2021-08-31},
	file = {Full Text:C\:\\Users\\Too_Faeded\\Zotero\\storage\\7L6LB7SB\\Grassia et al. - 2021 - Machine learning dismantling and early-warning sig.pdf:application/pdf},
    year = 2021,
}

@article{albert_error_2000,
	title = {Error and Attack Tolerance of Complex Networks},
	volume = {406},
	doi = {10.1038/35019019},
	abstract = {Many complex systems, such as communication networks, display a surprising degree of robustness: while key components regularly malfunction, local failures rarely lead to the loss of the global information-carrying ability of the network. The stability of these complex systems is often attributed to the redundant wiring of the functional web defined by the systems' components. In this paper we demonstrate that error tolerance is not shared by all redundant systems, but it is displayed only by a class of inhomogeneously wired networks, called scale-free networks. We find that scale-free networks, describing a number of systems, such as the World Wide Web, Internet, social networks or a cell, display an unexpected degree of robustness, the ability of their nodes to communicate being unaffected by even unrealistically high failure rates. However, error tolerance comes at a high price: these networks are extremely vulnerable to attacks, i.e. to the selection and removal of a few nodes that play the most important role in assuring the network's connectivity. Comment: 14 pages, 4 figures, Latex},
	journaltitle = {Nature},
    journal = {Nature},
	shortjournal = {Nature},
	author = {Albert, Rita and Jeong, Hawoong and Barabasi, Albert-Laszlo},
	date = {2000-08-03},
	file = {Submitted Version:C\:\\Users\\Too_Faeded\\Zotero\\storage\\ERGSM5IP\\Albert et al. - 2000 - Error and Attack Tolerance of Complex Networks.pdf:application/pdf},
    year = 2000,
}

@article{gelenbe_function_1999,
	title = {Function approximation with spiked random networks},
	volume = {10},
	issn = {1941-0093},
	doi = {10.1109/72.737488},
	abstract = {Examines the function approximation properties of the "random neural-network model" or {GNN}, The output of the {GNN} can be computed from the firing probabilities of selected neurons. We consider a feedforward bipolar {GNN} ({BGNN}) model which has both "positive and negative neurons" in the output layer, and prove that the {BGNN} is a universal function approximator. Specifically, for any f/spl isin/C([0,1]/sup s/) and any /spl epsiv/{\textgreater}0, we show that there exists a feedforward {BGNN} which approximates f uniformly with error less than /spl epsiv/. We also show that after some appropriate clamping operation on its output, the feedforward {GNN} is also a universal function approximator.},
	pages = {3--9},
	number = {1},
	journaltitle = {{IEEE} Transactions on Neural Networks},
    journal = {{IEEE} Transactions on Neural Networks},
	author = {Gelenbe, E. and Mao, Zhi-Hong and Li, Yan-Da},
	date = {1999-01},
	note = {Conference Name: {IEEE} Transactions on Neural Networks},
	keywords = {Adaptive control, Clamps, Data compression, Function approximation, Mathematical model, Multi-layer neural network, Neural networks, Neurons, Pattern recognition},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Too_Faeded\\Zotero\\storage\\ERKT73UG\\737488.html:text/html},
    year = 1999,
}

@article{silver_general_2018,
	title = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
	volume = {362},
	url = {https://www.science.org/doi/abs/10.1126/science.aar6404},
	doi = {10.1126/science.aar6404},
	pages = {1140--1144},
	number = {6419},
	journaltitle = {Science},
    journal = {Science},
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	urldate = {2022-04-19},
	date = {2018-12-07},
	note = {Publisher: American Association for the Advancement of Science},
	file = {Submitted Version:C\:\\Users\\Too_Faeded\\Zotero\\storage\\MIV324A2\\Silver et al. - 2018 - A general reinforcement learning algorithm that ma.pdf:application/pdf},
    year = 2018,
}

@article{moravcik_deepstack_2017,
	title = {{DeepStack}: Expert-level artificial intelligence in heads-up no-limit poker},
	volume = {356},
	url = {https://www.science.org/doi/abs/10.1126/science.aam6960},
	doi = {10.1126/science.aam6960},
	shorttitle = {{DeepStack}},
	pages = {508--513},
	number = {6337},
	journaltitle = {Science},
    journal = {Science},
	author = {Moravƒç√≠k, Matej and Schmid, Martin and Burch, Neil and Lis√Ω, Viliam and Morrill, Dustin and Bard, Nolan and Davis, Trevor and Waugh, Kevin and Johanson, Michael and Bowling, Michael},
	urldate = {2022-04-19},
	date = {2017-05-05},
	note = {Publisher: American Association for the Advancement of Science},
	file = {Submitted Version:C\:\\Users\\Too_Faeded\\Zotero\\storage\\JUHRN94E\\Moravƒç√≠k et al. - 2017 - DeepStack Expert-level artificial intelligence in.pdf:application/pdf},
    year = 2017,
}

@article{vinyals_grandmaster_2019,
	title = {Grandmaster level in {StarCraft} {II} using multi-agent reinforcement learning},
	volume = {575},
	rights = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-019-1724-z},
	doi = {10.1038/s41586-019-1724-z},
	abstract = {Many real-world applications require artificial agents to compete and coordinate with other agents in complex environments. As a stepping stone to this goal, the domain of {StarCraft} has emerged as an important challenge for artificial intelligence research, owing to its iconic and enduring status among the most difficult professional esports and its relevance to the real world in terms of its raw complexity and multi-agent challenges. Over the course of a decade and numerous competitions1‚Äì3, the strongest agents have simplified important aspects of the game, utilized superhuman capabilities, or employed hand-crafted sub-systems4. Despite these advantages, no previous agent has come close to matching the overall skill of top {StarCraft} players. We chose to address the challenge of {StarCraft} using general-purpose learning methods that are in principle applicable to other complex domains: a multi-agent reinforcement learning algorithm that uses data from both human and agent games within a diverse league of continually adapting strategies and counter-strategies, each represented by deep neural networks5,6. We evaluated our agent, {AlphaStar}, in the full game of {StarCraft} {II}, through a series of online games against human players. {AlphaStar} was rated at Grandmaster level for all three {StarCraft} races and above 99.8\% of officially ranked human players.},
	pages = {350--354},
	number = {7782},
	journaltitle = {Nature},
    journal = {Nature},
	author = {Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M. and Mathieu, Micha√´l and Dudzik, Andrew and Chung, Junyoung and Choi, David H. and Powell, Richard and Ewalds, Timo and Georgiev, Petko and Oh, Junhyuk and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Huang, Aja and Sifre, Laurent and Cai, Trevor and Agapiou, John P. and Jaderberg, Max and Vezhnevets, Alexander S. and Leblond, R√©mi and Pohlen, Tobias and Dalibard, Valentin and Budden, David and Sulsky, Yury and Molloy, James and Paine, Tom L. and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Wu, Yuhuai and Ring, Roman and Yogatama, Dani and W√ºnsch, Dario and {McKinney}, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Kavukcuoglu, Koray and Hassabis, Demis and Apps, Chris and Silver, David},
	urldate = {2022-04-19},
	date = {2019-11},
	langid = {english},
	note = {Number: 7782
Publisher: Nature Publishing Group},
	keywords = {Computer science, Statistics},
	file = {Snapshot:C\:\\Users\\Too_Faeded\\Zotero\\storage\\39VYZTXD\\s41586-019-1724-z.html:text/html},
    year = 2019,
}

@inproceedings{dutta_improving_2018,
	title = {Improving {CNN}-{RNN} Hybrid Networks for Handwriting Recognition},
	doi = {10.1109/ICFHR-2018.2018.00023},
	abstract = {The success of deep learning based models have centered around recent architectures and the availability of large scale annotated data. In this work, we explore these two factors systematically for improving handwritten recognition for scanned off-line document images. We propose a modified {CNN}-{RNN} hybrid architecture with a major focus on effective training using: (i) efficient initialization of network using synthetic data for pretraining, (ii) image normalization for slant correction and (iii) domain specific data transformation and distortion for learning important invariances. We perform a detailed ablation study to analyze the contribution of individual modules and present state of art results for the task of unconstrained line and word recognition on popular datasets such as {IAM}, {RIMES} and {GW}.},
	eventtitle = {2018 16th International Conference on Frontiers in Handwriting Recognition ({ICFHR})},
	pages = {80--85},
	booktitle = {2018 16th International Conference on Frontiers in Handwriting Recognition ({ICFHR})},
    book = {2018 16th International Conference on Frontiers in Handwriting Recognition ({ICFHR})},
	author = {Dutta, Kartik and Krishnan, Praveen and Mathew, Minesh and Jawahar, C.V.},
	date = {2018-08},
	keywords = {Decoding, Distortion, Feature extraction, Handwriting recognition, Handwriting recognition, {CNN} {RNN} network, Data augmentation, Image pre-processing, Hidden Markov models, Image recognition, Training},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Too_Faeded\\Zotero\\storage\\EQ9ES3B4\\8563230.html:text/html},
    year = 2018,
}

@inproceedings{balaban_deep_2015,
	title = {Deep learning and face recognition: the state of the art},
	volume = {9457},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/9457/94570B/Deep-learning-and-face-recognition--the-state-of-the/10.1117/12.2181526.full},
	doi = {10.1117/12.2181526},
	shorttitle = {Deep learning and face recognition},
	abstract = {Deep Neural Networks ({DNNs}) have established themselves as a dominant technique in machine learning. {DNNs} have been top performers on a wide variety of tasks including image classification, speech recognition, and face recognition.$^{\textrm{1-3}}$ Convolutional neural networks ({CNNs}) have been used in nearly all of the top performing methods on the Labeled Faces in the Wild ({LFW}) dataset.$^{\textrm{3-6}}$ In this talk and accompanying paper, I attempt to provide a review and summary of the deep learning techniques used in the state-of-the-art. In addition, I highlight the need for both larger and more challenging public datasets to benchmark these systems. Despite the ability of {DNNs} and autoencoders to perform unsupervised feature learning, modern facial recognition pipelines still require domain specific engineering in the form of re-alignment. For example, in Facebook's recent {DeepFace} paper, a 3D "frontalization" step lies at the beginning of the pipeline. This step creates a 3D face model for the incoming image and then uses a series of affine transformations of the fiducial points to "frontalize" the image. This step enables the {DeepFace} system to use a neural network architecture with locally connected layers without weight sharing as opposed to standard convolutional layers.$^{\textrm{6}}$ Deep learning techniques combined with large datasets have allowed research groups to surpass human level performance on the {LFW} dataset.$^{\textrm{3, 5}}$ The high accuracy (99.63\% for {FaceNet} at the time of publishing) and utilization of outside data (hundreds of millions of images in the case of Google's {FaceNet}) suggest that current face verification benchmarks such as {LFW} may not be challenging enough, nor provide enough data, for current techniques.$^{\textrm{3, 5}}$ There exist a variety of organizations with mobile photo sharing applications that would be capable of releasing a very large scale and highly diverse dataset of facial images captured on mobile devices. Such an "{ImageNet} for Face Recognition" would likely receive a warm welcome from researchers and practitioners alike.},
	eventtitle = {Biometric and Surveillance Technology for Human and Activity Identification {XII}},
	pages = {68--75},
	booktitle = {Biometric and Surveillance Technology for Human and Activity Identification {XII}},
    book = {Biometric and Surveillance Technology for Human and Activity Identification {XII}},
	publisher = {{SPIE}},
	author = {Balaban, Stephen},
	urldate = {2022-04-19},
	date = {2015-05-15},
	file = {Snapshot:C\:\\Users\\Too_Faeded\\Zotero\\storage\\XC99BXI3\\12.2181526.html:text/html;Submitted Version:C\:\\Users\\Too_Faeded\\Zotero\\storage\\LPSW4A2F\\Balaban - 2015 - Deep learning and face recognition the state of t.pdf:application/pdf},
    year = 2015,
}

@Article{Fan2020,
    author={Fan, Changjun
    and Zeng, Li
    and Sun, Yizhou
    and Liu, Yang-Yu},
    title={Finding key players in complex networks through deep reinforcement learning},
    journal={Nature Machine Intelligence},
    year={2020},
    month={Jun},
    day={01},
    volume={2},
    number={6},
    pages={317-324},
    abstract={Finding an optimal set of nodes, called key players, whose activation (or removal) would maximally enhance (or degrade) a certain network functionality, is a fundamental class of problems in network science. Potential applications include network immunization, epidemic control, drug design and viral marketing. Due to their general NP-hard nature, these problems typically cannot be solved by exact algorithms with polynomial time complexity. Many approximate and heuristic strategies have been proposed to deal with specific application scenarios. Yet, we still lack a unified framework to efficiently solve this class of problems. Here, we introduce a deep reinforcement learning framework FINDER, which can be trained purely on small synthetic networks generated by toy models and then applied to a wide spectrum of application scenarios. Extensive experiments under various problem settings demonstrate that FINDER significantly outperforms existing methods in terms of solution quality. Moreover, it is several orders of magnitude faster than existing methods for large networks. The presented framework opens up a new direction of using deep learning techniques to understand the organizing principle of complex networks, which enables us to design more robust networks against both attacks and failures.},
    issn={2522-5839},
    doi={10.1038/s42256-020-0177-2},
    url={https://doi.org/10.1038/s42256-020-0177-2},
}

@article{bak1987,
  title = {Self-organized criticality: An explanation of the 1/f noise},
  author = {Bak, Per and Tang, Chao and Wiesenfeld, Kurt},
  journal = {Phys. Rev. Lett.},
  volume = {59},
  issue = {4},
  pages = {381--384},
  numpages = {0},
  year = {1987},
  month = {Jul},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.59.381},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.59.381}
}

@article{bak1988,
  title = {Self-organized criticality},
  author = {Bak, Per and Tang, Chao and Wiesenfeld, Kurt},
  journal = {Phys. Rev. A},
  volume = {38},
  issue = {1},
  pages = {364--374},
  numpages = {0},
  year = {1988},
  month = {Jul},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevA.38.364},
  url = {https://link.aps.org/doi/10.1103/PhysRevA.38.364}
}

@article{cybenko1989approximation,
  title={Approximation by superpositions of a sigmoidal function},
  author={Cybenko, George},
  journal={Mathematics of control, signals and systems},
  volume={2},
  number={4},
  pages={303--314},
  year={1989},
  publisher={Springer}
}

@article{hornik1990universal,
  title={Universal approximation of an unknown mapping and its derivatives using multilayer feedforward networks},
  author={Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  journal={Neural networks},
  volume={3},
  number={5},
  pages={551--560},
  year={1990},
  publisher={Elsevier}
}

@inproceedings{nair2010rectified,
  title={Rectified linear units improve restricted boltzmann machines},
  author={Nair, Vinod and Hinton, Geoffrey E},
  booktitle={Proceedings of the 27th international conference on machine learning (ICML-10)},
  pages={807--814},
  year={2010}
}

@article{agarap2018,
  author       = {Abien Fred Agarap},
  title        = {Deep Learning using Rectified Linear Units (ReLU)},
  journal      = {CoRR},
  volume       = {abs/1803.08375},
  year         = {2018},
  url          = {http://arxiv.org/abs/1803.08375},
  eprinttype    = {arXiv},
  eprint       = {1803.08375},
  timestamp    = {Mon, 13 Aug 2018 16:47:13 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1803-08375.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{watkins1989learning,
  title={Learning from delayed rewards},
  author={Watkins, Christopher John Cornish Hellaby},
  year={1989},
  publisher={King's College, Cambridge United Kingdom}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@article{bellman1957dynamic,
  title={Dynamic programming and statistical communication theory},
  author={Bellman, Richard and Kalaba, Robert},
  journal={Proceedings of the National Academy of Sciences},
  volume={43},
  number={8},
  pages={749--751},
  year={1957},
  publisher={National Acad Sciences}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@article{sutton1999policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
  journal={Advances in neural information processing systems},
  volume={12},
  year={1999}
}
@article{nash1950equilibrium,
  title={Equilibrium points in n-person games},
  author={Nash Jr, John F},
  journal={Proceedings of the national academy of sciences},
  volume={36},
  number={1},
  pages={48--49},
  year={1950},
  publisher={National Acad Sciences}
}

@book{brown1950solutions,
  title={Solutions of games by differential equations},
  author={Brown, George W and Von Neumann, John},
  year={1950},
  publisher={Rand Corporation}
}

@article{Christensen1993,
  title = {Sandpile models with and without an underlying spatial structure},
  author = {Christensen, Kim and Olami, Zeev},
  journal = {Phys. Rev. E},
  volume = {48},
  issue = {5},
  pages = {3361--3372},
  numpages = {0},
  year = {1993},
  month = {Nov},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.48.3361},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.48.3361}
}

@article{brummitt2012suppressing,
  title={Suppressing cascades of load in interdependent networks},
  author={Brummitt, Charles D and D‚ÄôSouza, Raissa M and Leicht, Elizabeth A},
  journal={Proceedings of the national academy of sciences},
  volume={109},
  number={12},
  pages={E680--E689},
  year={2012},
  publisher={National Acad Sciences}
}

@article{Bhaumik2013,
  title = {Critical properties of a dissipative sandpile model on small-world networks},
  author = {Bhaumik, Himangsu and Santra, S. B.},
  journal = {Phys. Rev. E},
  volume = {88},
  issue = {6},
  pages = {062817},
  numpages = {12},
  year = {2013},
  month = {Dec},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.88.062817},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.88.062817}
}

@article{Vieira2007,
  title = {Analytical approach to directed sandpile models on the Apollonian network},
  author = {Vieira, Andr\'e P. and Andrade, Jos\'e S. and Herrmann, Hans J. and Andrade, Roberto F. S.},
  journal = {Phys. Rev. E},
  volume = {76},
  issue = {2},
  pages = {026111},
  numpages = {8},
  year = {2007},
  month = {Aug},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.76.026111},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.76.026111}
}

@article{buldyrev2010catastrophic,
  title={Catastrophic cascade of failures in interdependent networks},
  author={Buldyrev, Sergey V and Parshani, Roni and Paul, Gerald and Stanley, H Eugene and Havlin, Shlomo},
  journal={Nature},
  volume={464},
  number={7291},
  pages={1025--1028},
  year={2010},
  publisher={Nature Publishing Group UK London}
}

@article{rosato2008modelling,
  title={Modelling interdependent infrastructures using interacting dynamical models},
  author={Rosato, Vittorio and Issacharoff, Limor and Tiriticco, Fabio and Meloni, Sandro and Porcellinis, S and Setola, Roberto},
  journal={International Journal of Critical Infrastructures},
  volume={4},
  number={1-2},
  pages={63--79},
  year={2008},
  publisher={Inderscience Publishers}
}

@article{Motter2002,
  title = {Cascade-based attacks on complex networks},
  author = {Motter, Adilson E. and Lai, Ying-Cheng},
  journal = {Phys. Rev. E},
  volume = {66},
  issue = {6},
  pages = {065102},
  numpages = {4},
  year = {2002},
  month = {Dec},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.66.065102},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.66.065102}
}

@article{DSouza2013,
  title = {Controlling Self-Organizing Dynamics on Networks Using Models that Self-Organize},
  author = {No\"el, Pierre-Andr\'e and Brummitt, Charles D. and D'Souza, Raissa M.},
  journal = {Phys. Rev. Lett.},
  volume = {111},
  issue = {7},
  pages = {078701},
  numpages = {5},
  year = {2013},
  month = {Aug},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.111.078701},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.111.078701}
}

@article{albert2000attack,
  title={Attack and error tolerance in complex networks},
  author={Albert, Reka},
  journal={Nature},
  volume={406},
  pages={387--482},
  year={2000}
}

@article{cohen2001breakdown,
  title={Breakdown of the internet under intentional attack},
  author={Cohen, Reuven and Erez, Keren and Ben-Avraham, Daniel and Havlin, Shlomo},
  journal={Physical review letters},
  volume={86},
  number={16},
  pages={3682},
  year={2001},
  publisher={APS}
}

@article{dobson2007complex,
  title={Complex systems analysis of series of blackouts: Cascading failure, critical points, and self-organization},
  author={Dobson, Ian and Carreras, Benjamin A and Lynch, Vickie E and Newman, David E},
  journal={Chaos: An Interdisciplinary Journal of Nonlinear Science},
  volume={17},
  number={2},
  year={2007},
  publisher={AIP Publishing}
}

@inproceedings{bakshy2011everyone,
  title={Everyone's an influencer: quantifying influence on twitter},
  author={Bakshy, Eytan and Hofman, Jake M and Mason, Winter A and Watts, Duncan J},
  booktitle={Proceedings of the fourth ACM international conference on Web search and data mining},
  pages={65--74},
  year={2011}
}